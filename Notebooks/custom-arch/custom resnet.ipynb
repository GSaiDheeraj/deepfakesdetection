{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cd3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saidh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "# from keras.utils import plot_model\n",
    "# from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7392c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = \"C:/Users/saidh/Downloads/archive/real_vs_fake/real-vs-fake/\"\n",
    "\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "image_gen1 =  ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "train_flow= image_gen1.flow_from_directory(\n",
    "    base_path + 'train/',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode ='binary'\n",
    ")\n",
    "\n",
    "valid_flow = image_gen1.flow_from_directory(\n",
    "    base_path + 'valid/',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "test_flow = image_gen1.flow_from_directory(\n",
    "    base_path + 'test/',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 1,\n",
    "    shuffle = False,\n",
    "    class_mode ='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692b1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9db68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X: tf.Tensor, level: int, block: int, filters: List[int]) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Creates an identity block (see figure 3.1 from readme)\n",
    "\n",
    "    Input:\n",
    "        X - input tensor of shape (m, height_prev, width_prev, chan_prev)\n",
    "        level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in the readme file)\n",
    "              - level names have the form: conv2_x, conv3_x ... conv5_x\n",
    "        block - each conceptual level has multiple blocks (1 identity and several convolutional blocks)\n",
    "                block is the number of this block within its conceptual layer\n",
    "                i.e. first block from level 2 will be named conv2_1\n",
    "        filters - a list on integers, each of them defining the number of filters in each convolutional layer\n",
    "\n",
    "    Output:\n",
    "        X - tensor (m, height, width, chan)\n",
    "    \"\"\"\n",
    "\n",
    "    # layers will be called conv{level}_iden{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # the shortcut branch of the identity block\n",
    "    # takes the value of the block input\n",
    "    X_shortcut = X\n",
    "\n",
    "    # first convolutional layer (plus batch norm & relu activation, of course)\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1),\n",
    "               padding='same', name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1),\n",
    "               padding='valid', name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "\n",
    "    # relu activation at the end of the block\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7379e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X: tf.Tensor, level: int, block: int, filters: List[int], s: Tuple[int,int,int]=(2, 2)) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Creates a convolutional block (see figure 3.1 from readme)\n",
    "\n",
    "    Input:\n",
    "        X - input tensor of shape (m, height_prev, width_prev, chan_prev)\n",
    "        level - integer, one of the 5 levels that our networks is conceptually divided into (see figure 3.1 in the readme file)\n",
    "              - level names have the form: conv2_x, conv3_x ... conv5_x\n",
    "        block - each conceptual level has multiple blocks (1 identity and several convolutional blocks)\n",
    "                block is the number of this block within its conceptual layer\n",
    "                i.e. first block from level 2 will be named conv2_1\n",
    "        filters - a list on integers, each of them defining the number of filters in each convolutional layer\n",
    "        s   - stride of the first layer;\n",
    "            - a conv layer with a filter that has a stride of 2 will reduce the width and height of its input by half\n",
    "\n",
    "    Output:\n",
    "        X - tensor (m, height, width, chan)\n",
    "    \"\"\"\n",
    "\n",
    "    # layers will be called conv{level}_{block}_{convlayer_number_within_block}'\n",
    "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
    "\n",
    "    # unpack number of filters to be used for each conv layer\n",
    "    f1, f2, f3 = filters\n",
    "\n",
    "    # the shortcut branch of the convolutional block\n",
    "    X_shortcut = X\n",
    "\n",
    "    # first convolutional layer\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "               name=conv_name.format(layer=1, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
    "\n",
    "    # second convolutional layer\n",
    "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "               name=conv_name.format(layer=2, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
    "    X = Activation('relu', name=conv_name.format(layer=2, type='relu'))(X)\n",
    "\n",
    "    # third convolutional layer\n",
    "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
    "               name=conv_name.format(layer=3, type='conv'),\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
    "\n",
    "    # shortcut path\n",
    "    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=s, padding='valid',\n",
    "                        name=conv_name.format(layer='short', type='conv'),\n",
    "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3, name=conv_name.format(layer='short', type='bn'))(X_shortcut)\n",
    "\n",
    "    # add shortcut branch to main path\n",
    "    X = Add()([X, X_shortcut])\n",
    "\n",
    "    # nonlinearity\n",
    "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ef48e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_size: Tuple[int,int,int], classes: int) -> Model:\n",
    "    \"\"\"\n",
    "        Builds the ResNet50 model (see figure 4.2 from readme)\n",
    "\n",
    "        Input:\n",
    "            - input_size - a (height, width, chan) tuple, the shape of the input images\n",
    "            - classes - number of classes the model must learn\n",
    "\n",
    "        Output:\n",
    "            model - a Keras Model() instance\n",
    "    \"\"\"\n",
    "\n",
    "    # tensor placeholder for the model's input\n",
    "    X_input = Input(input_size)\n",
    "\n",
    "    ### Level 1 ###\n",
    "\n",
    "    # padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # convolutional layer, followed by batch normalization and relu activation\n",
    "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "               name='conv1_1_1_conv',\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='conv1_1_1_nb')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### Level 2 ###\n",
    "\n",
    "    # max pooling layer to halve the size coming from the previous layer\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=2, block=1, filters=[64, 64, 256], s=(1, 1))\n",
    "\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=2, block=2, filters=[64, 64, 256])\n",
    "    X = identity_block(X, level=2, block=3, filters=[64, 64, 256])\n",
    "\n",
    "    ### Level 3 ###\n",
    "\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=3, block=1, filters=[128, 128, 512], s=(2, 2))\n",
    "\n",
    "    # 3x identity blocks\n",
    "    X = identity_block(X, level=3, block=2, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=3, filters=[128, 128, 512])\n",
    "    X = identity_block(X, level=3, block=4, filters=[128, 128, 512])\n",
    "\n",
    "    ### Level 4 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=4, block=1, filters=[256, 256, 1024], s=(2, 2))\n",
    "    # 5x identity blocks\n",
    "    X = identity_block(X, level=4, block=2, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=3, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=4, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=5, filters=[256, 256, 1024])\n",
    "    X = identity_block(X, level=4, block=6, filters=[256, 256, 1024])\n",
    "\n",
    "    ### Level 5 ###\n",
    "    # 1x convolutional block\n",
    "    X = convolutional_block(X, level=5, block=1, filters=[512, 512, 2048], s=(2, 2))\n",
    "    # 2x identity blocks\n",
    "    X = identity_block(X, level=5, block=2, filters=[512, 512, 2048])\n",
    "    X = identity_block(X, level=5, block=3, filters=[512, 512, 2048])\n",
    "\n",
    "    # Pooling layers\n",
    "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # Output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='softmax', name='fc_' + str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5ea565",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_size = (224, 224, 3), classes =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20ecae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1_1_conv (Conv2D)         (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1_1_nb (BatchNormalizatio (None, 112, 112, 64) 256         conv1_1_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           conv1_1_1_nb[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1_conv (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_1_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1_relu (Activation)     (None, 55, 55, 64)   0           conv2_1_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_2_conv (Conv2D)         (None, 55, 55, 64)   36928       conv2_1_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_2_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_1_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_2_relu (Activation)     (None, 55, 55, 64)   0           conv2_1_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3_conv (Conv2D)         (None, 55, 55, 256)  16640       conv2_1_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_short_conv (Conv2D)     (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3_bn (BatchNormalizatio (None, 55, 55, 256)  1024        conv2_1_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_short_bn (BatchNormaliz (None, 55, 55, 256)  1024        conv2_1_short_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           conv2_1_3_bn[0][0]               \n",
      "                                                                 conv2_1_short_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3_relu (Activation)     (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1_conv (Conv2D)         (None, 55, 55, 64)   16448       conv2_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_2_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1_relu (Activation)     (None, 55, 55, 64)   0           conv2_2_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_2_conv (Conv2D)         (None, 55, 55, 64)   36928       conv2_2_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_2_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_2_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_2_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3_conv (Conv2D)         (None, 55, 55, 256)  16640       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3_bn (BatchNormalizatio (None, 55, 55, 256)  1024        conv2_2_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_3_bn[0][0]               \n",
      "                                                                 conv2_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3_relu (Activation)     (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1_conv (Conv2D)         (None, 55, 55, 64)   16448       conv2_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_3_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1_relu (Activation)     (None, 55, 55, 64)   0           conv2_3_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_2_conv (Conv2D)         (None, 55, 55, 64)   36928       conv2_3_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_2_bn (BatchNormalizatio (None, 55, 55, 64)   256         conv2_3_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_3_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3_conv (Conv2D)         (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3_bn (BatchNormalizatio (None, 55, 55, 256)  1024        conv2_3_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_3_bn[0][0]               \n",
      "                                                                 conv2_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3_relu (Activation)     (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1_conv (Conv2D)         (None, 28, 28, 128)  32896       conv2_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_1_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1_relu (Activation)     (None, 28, 28, 128)  0           conv3_1_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_2_conv (Conv2D)         (None, 28, 28, 128)  147584      conv3_1_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_2_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_1_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_2_relu (Activation)     (None, 28, 28, 128)  0           conv3_1_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3_conv (Conv2D)         (None, 28, 28, 512)  66048       conv3_1_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_short_conv (Conv2D)     (None, 28, 28, 512)  131584      conv2_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3_bn (BatchNormalizatio (None, 28, 28, 512)  2048        conv3_1_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_short_bn (BatchNormaliz (None, 28, 28, 512)  2048        conv3_1_short_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_3_bn[0][0]               \n",
      "                                                                 conv3_1_short_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3_relu (Activation)     (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1_conv (Conv2D)         (None, 28, 28, 128)  65664       conv3_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_2_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1_relu (Activation)     (None, 28, 28, 128)  0           conv3_2_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_2_conv (Conv2D)         (None, 28, 28, 128)  147584      conv3_2_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_2_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_2_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 28, 28, 128)  0           conv3_2_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3_conv (Conv2D)         (None, 28, 28, 512)  66048       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3_bn (BatchNormalizatio (None, 28, 28, 512)  2048        conv3_2_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_3_bn[0][0]               \n",
      "                                                                 conv3_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3_relu (Activation)     (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1_conv (Conv2D)         (None, 28, 28, 128)  65664       conv3_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_3_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1_relu (Activation)     (None, 28, 28, 128)  0           conv3_3_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_2_conv (Conv2D)         (None, 28, 28, 128)  147584      conv3_3_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_2_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_3_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 128)  0           conv3_3_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3_conv (Conv2D)         (None, 28, 28, 512)  66048       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3_bn (BatchNormalizatio (None, 28, 28, 512)  2048        conv3_3_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_3_bn[0][0]               \n",
      "                                                                 conv3_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3_relu (Activation)     (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1_conv (Conv2D)         (None, 28, 28, 128)  65664       conv3_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_4_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1_relu (Activation)     (None, 28, 28, 128)  0           conv3_4_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_2_conv (Conv2D)         (None, 28, 28, 128)  147584      conv3_4_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_2_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv3_4_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 128)  0           conv3_4_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3_conv (Conv2D)         (None, 28, 28, 512)  66048       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3_bn (BatchNormalizatio (None, 28, 28, 512)  2048        conv3_4_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_3_bn[0][0]               \n",
      "                                                                 conv3_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3_relu (Activation)     (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1_conv (Conv2D)         (None, 14, 14, 256)  131328      conv3_4_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_1_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_1_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_1_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_1_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_2_relu (Activation)     (None, 14, 14, 256)  0           conv4_1_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      conv4_1_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_short_conv (Conv2D)     (None, 14, 14, 1024) 525312      conv3_4_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_1_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_short_bn (BatchNormaliz (None, 14, 14, 1024) 4096        conv4_1_short_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_3_bn[0][0]               \n",
      "                                                                 conv4_1_short_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3_relu (Activation)     (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1_conv (Conv2D)         (None, 14, 14, 256)  262400      conv4_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_2_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_2_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_2_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_2_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 14, 14, 256)  0           conv4_2_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_2_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_3_bn[0][0]               \n",
      "                                                                 conv4_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3_relu (Activation)     (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1_conv (Conv2D)         (None, 14, 14, 256)  262400      conv4_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_3_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_3_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_3_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_3_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 14, 14, 256)  0           conv4_3_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_3_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_3_bn[0][0]               \n",
      "                                                                 conv4_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3_relu (Activation)     (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1_conv (Conv2D)         (None, 14, 14, 256)  262400      conv4_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_4_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_4_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_4_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_4_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 14, 14, 256)  0           conv4_4_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_4_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_3_bn[0][0]               \n",
      "                                                                 conv4_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3_relu (Activation)     (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1_conv (Conv2D)         (None, 14, 14, 256)  262400      conv4_4_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_5_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_5_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_5_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_5_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 14, 14, 256)  0           conv4_5_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_5_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_3_bn[0][0]               \n",
      "                                                                 conv4_4_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3_relu (Activation)     (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1_conv (Conv2D)         (None, 14, 14, 256)  262400      conv4_5_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_6_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1_relu (Activation)     (None, 14, 14, 256)  0           conv4_6_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_2_conv (Conv2D)         (None, 14, 14, 256)  590080      conv4_6_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_2_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv4_6_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 14, 14, 256)  0           conv4_6_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3_conv (Conv2D)         (None, 14, 14, 1024) 263168      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3_bn (BatchNormalizatio (None, 14, 14, 1024) 4096        conv4_6_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_3_bn[0][0]               \n",
      "                                                                 conv4_5_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3_relu (Activation)     (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1_conv (Conv2D)         (None, 7, 7, 512)    524800      conv4_6_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_1_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1_relu (Activation)     (None, 7, 7, 512)    0           conv5_1_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_2_conv (Conv2D)         (None, 7, 7, 512)    2359808     conv5_1_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_2_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_1_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_2_relu (Activation)     (None, 7, 7, 512)    0           conv5_1_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3_conv (Conv2D)         (None, 7, 7, 2048)   1050624     conv5_1_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_short_conv (Conv2D)     (None, 7, 7, 2048)   2099200     conv4_6_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3_bn (BatchNormalizatio (None, 7, 7, 2048)   8192        conv5_1_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_short_bn (BatchNormaliz (None, 7, 7, 2048)   8192        conv5_1_short_conv[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_3_bn[0][0]               \n",
      "                                                                 conv5_1_short_bn[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3_relu (Activation)     (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1_conv (Conv2D)         (None, 7, 7, 512)    1049088     conv5_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_2_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1_relu (Activation)     (None, 7, 7, 512)    0           conv5_2_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_2_conv (Conv2D)         (None, 7, 7, 512)    2359808     conv5_2_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_2_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_2_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 512)    0           conv5_2_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3_conv (Conv2D)         (None, 7, 7, 2048)   1050624     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3_bn (BatchNormalizatio (None, 7, 7, 2048)   8192        conv5_2_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_3_bn[0][0]               \n",
      "                                                                 conv5_1_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3_relu (Activation)     (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1_conv (Conv2D)         (None, 7, 7, 512)    1049088     conv5_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_3_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1_relu (Activation)     (None, 7, 7, 512)    0           conv5_3_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_2_conv (Conv2D)         (None, 7, 7, 512)    2359808     conv5_3_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_2_bn (BatchNormalizatio (None, 7, 7, 512)    2048        conv5_3_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 512)    0           conv5_3_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3_conv (Conv2D)         (None, 7, 7, 2048)   1050624     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3_bn (BatchNormalizatio (None, 7, 7, 2048)   8192        conv5_3_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_3_bn[0][0]               \n",
      "                                                                 conv5_2_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3_relu (Activation)     (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 3, 3, 2048)   0           conv5_3_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18432)        0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 1)            18433       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,606,145\n",
      "Trainable params: 23,553,025\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7e9482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saidh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy',optimizer= opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1e513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath = \"saved-final-model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d0ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saidh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node ResNet50/conv2_2_3_bn/FusedBatchNormV3 (defined at <ipython-input-11-7c3d613601a4>:10) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11908]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7c3d613601a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_flow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node ResNet50/conv2_2_3_bn/FusedBatchNormV3 (defined at <ipython-input-11-7c3d613601a4>:10) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_11908]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "train_steps = 100000//100\n",
    "valid_steps = 20000//100\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_flow,\n",
    "    epochs =15,\n",
    "    callbacks= callbacks_list,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = valid_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fb973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
